<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Poorman's Rust Enum in Python for ThePrimeagen's Lexer | Will Duke's Blog</title><meta name=keywords content><meta name=description content="A couple of months ago, I came across a video where the prolific streamer and Netflix dev known online as the ThePrimeagen live-coded a simple lexer for an interpreter inspired by the book Crafting Interpreters by Robert Nystrom. If you&rsquo;ve ever looked into what CPython actually does with your source code, you&rsquo;ll know that it parses the code into an abstract syntax tree, converts the tree into bytecode instructions (i.e. those *."><meta name=author content="Will Duke"><link rel=canonical href=https://willduke.github.io/posts/06-lexer/><meta name=google-site-verification content="YFLJWyfoiCPS_M6R4zxZe1XBpPlHZzrbEqFDpbmZXvs"><link crossorigin=anonymous href=/assets/css/stylesheet.53d97598899667e064f3ce6a3016e01bf8d751bc9fa264a5e95bbdcbee247dfa.css integrity="sha256-U9l1mImWZ+Bk885qMBbgG/jXUbyfomSl6Vu9y+4kffo=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://willduke.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://willduke.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://willduke.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://willduke.github.io/apple-touch-icon.png><link rel=mask-icon href=https://willduke.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-DW1P8KG3ES"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-DW1P8KG3ES",{anonymize_ip:!1})}</script><meta property="og:title" content="A Poorman's Rust Enum in Python for ThePrimeagen's Lexer"><meta property="og:description" content="A couple of months ago, I came across a video where the prolific streamer and Netflix dev known online as the ThePrimeagen live-coded a simple lexer for an interpreter inspired by the book Crafting Interpreters by Robert Nystrom. If you&rsquo;ve ever looked into what CPython actually does with your source code, you&rsquo;ll know that it parses the code into an abstract syntax tree, converts the tree into bytecode instructions (i.e. those *."><meta property="og:type" content="article"><meta property="og:url" content="https://willduke.github.io/posts/06-lexer/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-12T22:22:45-04:00"><meta property="article:modified_time" content="2023-08-12T22:22:45-04:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="A Poorman's Rust Enum in Python for ThePrimeagen's Lexer"><meta name=twitter:description content="A couple of months ago, I came across a video where the prolific streamer and Netflix dev known online as the ThePrimeagen live-coded a simple lexer for an interpreter inspired by the book Crafting Interpreters by Robert Nystrom. If you&rsquo;ve ever looked into what CPython actually does with your source code, you&rsquo;ll know that it parses the code into an abstract syntax tree, converts the tree into bytecode instructions (i.e. those *."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://willduke.github.io/posts/"},{"@type":"ListItem","position":2,"name":"A Poorman's Rust Enum in Python for ThePrimeagen's Lexer","item":"https://willduke.github.io/posts/06-lexer/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Poorman's Rust Enum in Python for ThePrimeagen's Lexer","name":"A Poorman\u0027s Rust Enum in Python for ThePrimeagen\u0027s Lexer","description":"A couple of months ago, I came across a video where the prolific streamer and Netflix dev known online as the ThePrimeagen live-coded a simple lexer for an interpreter inspired by the book Crafting Interpreters by Robert Nystrom. If you\u0026rsquo;ve ever looked into what CPython actually does with your source code, you\u0026rsquo;ll know that it parses the code into an abstract syntax tree, converts the tree into bytecode instructions (i.e. those *.","keywords":[],"articleBody":"A couple of months ago, I came across a video where the prolific streamer and Netflix dev known online as the ThePrimeagen live-coded a simple lexer for an interpreter inspired by the book Crafting Interpreters by Robert Nystrom. If you’ve ever looked into what CPython actually does with your source code, you’ll know that it parses the code into an abstract syntax tree, converts the tree into bytecode instructions (i.e. those *.pyc files usually in a __pycache__ directory) and runs them on a virtual machine. But before it can do any of that, it has to “lex” the raw text of the file into meaningful tokens like def, True, etc. I was struck by the elegance of ThePrimeagen’s implementation in Rust, and so I set myself a task: how close can I get to the Rust version using Python?1\n(Sort of) Emulating Rust Enums in Python Even a superficial glance at the Rust lexer will give you an appreciation for Rust enums and pattern matching. In Rust, enums can contain data, so enumerating each of the token types that the lexer recognizes is straightforward:\npub enum Token { Ident(String), Int(String), Illegal, Eof, Assign, Bang, Dash, ... Return, True, False, } In Python, it’s similarly eas– uh, oh.\nPython enums just don’t work this way. Enum subclass members are expected to be singletons, so we’ll have to use a different abstraction. After some finagling, I landed on namedtuples as a suitable alternative.\nfrom collections import namedtuple class Token(TokenBase): Ident = namedtuple(\"Ident\", [\"value\"]) Int = namedtuple(\"Int\", [\"value\"]) Illegal = namedtuple(\"Illegal\", []) Eof = namedtuple(\"Eof\", []) Assign = namedtuple(\"Assign\", []) Bang = namedtuple(\"Bang\", []) Dash = namedtuple(\"Dash\", []) ... Return = namedtuple(\"Return\", []) True_ = namedtuple(\"True_\", []) False_ = namedtuple(\"False_\", []) Not nearly as pretty, but the advantage is that each member of Token is now a dynamically generated NamedTuple that only has a value attribute if the token type requires it. So identifiers like value in let value = 5; are captured in Token.Ident(\"value\"), but return tokens (Token.Return()) don’t carry around extra baggage.\nWhat’s TokenBase, you ask? Well, if you instantiate a member of the Token class without the base class, you’ll get something like:\n\u003e\u003e\u003e Token.Ident(\"val\") Ident(\"val\") \u003e\u003e\u003e Token.Dash() Dash() Close, but not quite as nice as the way that tokens are displayed in the Rust version: Token.Ident(\"val\"). TokenBase customizes the __repr__s for each of the namedtuples to look more like Rust. (It also modifies __eq__ and __neq__ so that empty namedtuples with different names do not compare equal!) Here’s the ugliness to make that work:\nclass TokenBase: def __init_subclass__(cls) -\u003e None: def _token_repr(self): name = self.__class__.__name__ return ( f\"Token.{name}({self.value!r})\" if hasattr(self, \"value\") else f\"Token.{name}\" ) def _token_eq(self, other): return repr(self) == repr(other) def _token_ne(self, other): return repr(self) != repr(other) for name, method in vars(cls).items(): if name.startswith(\"__\"): continue method.__repr__ = _token_repr method.__eq__ = _token_eq method.__ne__ = _token_ne The trick is that by using __init_subclass__, the __repr__, __eq__, and __neq__ implementations of the NamedTuple class attributes on Token will be overwritten when the class is imported. This way, Token.Ident(...) will be modified without ever instantiating Token.\nThe end result is that instantiating members of Token will create NamedTuple instances that behave a little bit more like Rust enums.\n\u003e\u003e\u003e Token.Ident(\"val\") Token.Ident('val') \u003e\u003e\u003e Token.Dash() Token.Dash \u003e\u003e\u003e Token.Dash() != Token.Return() True Shamelessly Copying (Most of) the Lexer Though Rust is a substantially more complex language than Python and has been designed with completely different tradeoffs in mind, both languages provide similar procedural syntax. What follows is a more or less direct port of the Lexer struct and its methods to peek or advance to the next character in the input text.\n@dataclass class Lexer: text: str position: int = 0 read_position: int = 0 ch: str = field(init=False, default=\"\") def __post_init__(self): self.read_char() def __iter__(self): while (token := self.next_token()) != Token.Eof(): yield token yield token def next_token(self): ... def peek(self): if self.read_position \u003c len(self.text): return self.text[self.read_position] def read_char(self): if self.read_position \u003e= len(self.text): self.ch = \"\" else: self.ch = self.text[self.read_position] self.position = self.read_position self.read_position += 1 def skip_whitespace(self): while self.ch.isspace(): self.read_char() def read_ident(self): pos = self.position while self.peek().isalpha() or self.peek() == \"_\": self.read_char() return self.input[pos : self.read_position] def read_int(self): pos = self.position while self.peek().isdigit(): self.read_char() return self.input[pos : self.read_position] The Lexer starts at position 0 and steps through the text each time next_token() is called. If the next token contains multiple characters or skippable whitespace, next_token() will advance the Lexer position to the end of the last token. The read_position will then correspond to the start of the next token (or whitespace).\nThe read_ident and read_int functions repeatedly peek at the next character in the input text, instructing the lexer to keep reading the next character until the end of the identifer or integer. The functions record the start and end positions so that they can slice into the input string to return a multi-character token.\nPython makes it easy to create custom iterables, so I added an __iter__ method which will make for token in lexer: print(token) work with no extra sweat!\nMatching match statements Things get interesting again when trying to implement next_token(). The Rust implentation uses a single match statement to identify each of the tokens defined in the lexer. In the python version, matching on individual characters ports directly:\ndef next_token(self): self.skip_whitespace() match self.ch: case \"{\": tok = Token.LSquirly() case \"}\": tok = Token.RSquirly() case \"(\": tok = Token.Lparen() case \")\": tok = Token.Rparen() ... In some cases, such as Token.Bang, and Token.NotEqual, the lexer peeks at the next character to see which token to emit. This ports over nicely as well:\ncase \"!\": if self.peek() == \"=\": self.read_char() tok = Token.NotEqual() else: tok = Token.Bang() The case for finding identifiers is particularly elegant in the Rust version: the following excerpt matches on any character that contains an alphabetic character or an underscore to find identifiers, and then uses a nested match statement to identify reserved keywords.\nmatch self.ch { ..., b'a'..=b'z' | b'A'..=b'Z' | b'_' =\u003e { let ident = self.read_ident(); return Ok(match ident.as_str() { \"fn\" =\u003e Token::Function, \"let\" =\u003e Token::Let, \"if\" =\u003e Token::If, \"false\" =\u003e Token::False, \"true\" =\u003e Token::True, \"return\" =\u003e Token::Return, \"else\" =\u003e Token::Else, _ =\u003e Token::Ident(ident), }); }, ... } The ..= is a convenient syntax for creating inclusive ranges that in this case span either the uppercase or lowercase alphabet. Python does not have a direct equivalent, but according to PEP 636, it does have match conditionals! Here’s what the equivalent looks like in Python:\ncase t if t.isalpha() or t == \"_\": match self.read_ident(): case \"fn\": tok = Token.Function() ... case _ as val: tok = Token.Ident(val) case t if t.isdigit(): tok = Token.Int(self.read_int()) Incidentally, this version supports unicode alphabetic characters as well!\nPutting it all together, we get:\ndef next_token(self): self.skip_whitespace() match self.ch: case \"{\": tok = Token.LSquirly() case \"}\": tok = Token.RSquirly() case \"(\": tok = Token.Lparen() case \")\": tok = Token.Rparen() case \",\": tok = Token.Comma() case \";\": tok = Token.Semicolon() case \"+\": tok = Token.Plus() case \"-\": tok = Token.Dash() case \"!\": if self.peek() == \"=\": self.read_char() tok = Token.NotEqual() else: tok = Token.Bang() case \"\u003e\": tok = Token.GreaterThan() case \"\u003c\": tok = Token.LessThan() case \"*\": tok = Token.Asterisk() case \"/\": tok = Token.ForwardSlash() case \"=\": if self.peek() == \"=\": self.read_char() tok = Token.Equal() else: tok = Token.Assign() case t if t.isalpha() or t == \"_\": match self.read_ident(): case \"fn\": tok = Token.Function() case \"let\": tok = Token.Let() case \"if\": tok = Token.If() case \"false\": tok = Token.False_() case \"true\": tok = Token.True_() case \"return\": tok = Token.Return() case \"else\": tok = Token.Else() case _ as val: tok = Token.Ident(val) case t if t.isdigit(): tok = Token.Int(self.read_int()) case \"\": tok = Token.Eof() case _: tok = Token.Illegal self.read_char() return tok Not bad!\nChecking our work The last task is to reimplement the tests. Here’s the smaller of the two tests in the reference, taking advantage of the __iter__ implementation that we added to the lexer:\ndef test_next_small(): text = \"=+(){},;\" lexer = Lexer(text) tokens = [ Token.Assign(), Token.Plus(), Token.Lparen(), Token.Rparen(), Token.LSquirly(), Token.RSquirly(), Token.Comma(), Token.Semicolon(), ] for exp, res in zip(tokens, lexer): print(f\"expected: {exp}, received {res}\") assert exp == res \u003e\u003e\u003e test_next_small() expected: Token.Assign, received Token.Assign expected: Token.Plus, received Token.Plus expected: Token.Lparen, received Token.Lparen expected: Token.Rparen, received Token.Rparen expected: Token.LSquirly, received Token.LSquirly expected: Token.RSquirly, received Token.RSquirly expected: Token.Comma, received Token.Comma expected: Token.Semicolon, received Token.Semicolon As usual, the full source for this post is available here.\nMany contributors submitted equivalent lexers in a variety of languages for comparison, including one in python that even includes a parser. ↩︎\n","wordCount":"1423","inLanguage":"en","datePublished":"2023-08-12T22:22:45-04:00","dateModified":"2023-08-12T22:22:45-04:00","author":{"@type":"Person","name":"Will Duke"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://willduke.github.io/posts/06-lexer/"},"publisher":{"@type":"Organization","name":"Will Duke's Blog","logo":{"@type":"ImageObject","url":"https://willduke.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://willduke.github.io/ accesskey=h title="Will Duke's Blog (Alt + H)"><img src=https://willduke.github.io/apple-touch-icon.png alt aria-label=logo height=30>Will Duke's Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://willduke.github.io/posts title=Posts><span>Posts</span></a></li><li><a href=https://willduke.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://willduke.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://willduke.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://willduke.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://willduke.github.io/posts/>Posts</a></div><h1 class=post-title>A Poorman's Rust Enum in Python for ThePrimeagen's Lexer</h1><div class=post-meta><span title='2023-08-12 22:22:45 -0400 -0400'>August 12, 2023</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1423 words&nbsp;·&nbsp;Will Duke&nbsp;|&nbsp;<a href=https://github.com/WillDuke/willduke.github.io/tree/main/content/posts/06-lexer.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#sort-of-emulating-rust-enums-in-python aria-label="(Sort of) Emulating Rust Enums in Python">(Sort of) Emulating Rust Enums in Python</a></li><li><a href=#shamelessly-copying-most-of-the-lexer aria-label="Shamelessly Copying (Most of) the Lexer">Shamelessly Copying (Most of) the Lexer</a></li><li><a href=#matching-match-statements aria-label="Matching match statements">Matching <code>match</code> statements</a></li><li><a href=#checking-our-work aria-label="Checking our work">Checking our work</a></li></ul></div></details></div><div class=post-content><p>A couple of months ago, I came across a video where the prolific streamer and Netflix dev known online as the ThePrimeagen <a href="https://www.youtube.com/watch?v=4TxOD2GmWU4">live-coded</a> <a href=https://github.com/ThePrimeagen/ts-rust-zig-deez/blob/master/rust/src/lexer/lexer.rs>a simple lexer</a> for an interpreter inspired by the book <a href=https://craftinginterpreters.com/>Crafting Interpreters</a> by Robert Nystrom. If you&rsquo;ve ever looked into what CPython actually does with your source code, you&rsquo;ll know that it parses the code into an abstract syntax tree, converts the tree into bytecode instructions (i.e. those <code>*.pyc</code> files usually in a <code>__pycache__</code> directory) and runs them on a virtual machine. But before it can do any of that, it has to &ldquo;lex&rdquo; the raw text of the file into meaningful tokens like <code>def</code>, <code>True</code>, etc. I was struck by the elegance of ThePrimeagen&rsquo;s implementation in Rust, and so I set myself a task: how close can I get to the Rust version using Python?<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></p><h2 id=sort-of-emulating-rust-enums-in-python>(Sort of) Emulating Rust Enums in Python<a hidden class=anchor aria-hidden=true href=#sort-of-emulating-rust-enums-in-python>#</a></h2><p>Even a superficial glance at the <a href=https://github.com/ThePrimeagen/ts-rust-zig-deez/blob/master/rust/src/lexer/lexer.rs>Rust lexer</a> will give you an appreciation for Rust enums and pattern matching. In Rust, enums can contain data, so enumerating each of the token types that the lexer recognizes is straightforward:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>pub</span> <span style=color:#66d9ef>enum</span> <span style=color:#a6e22e>Token</span> {
</span></span><span style=display:flex><span>    Ident(String),
</span></span><span style=display:flex><span>    Int(String),
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Illegal,
</span></span><span style=display:flex><span>    Eof,
</span></span><span style=display:flex><span>    Assign,
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    Bang,
</span></span><span style=display:flex><span>    Dash,
</span></span><span style=display:flex><span>    <span style=color:#f92672>..</span>.
</span></span><span style=display:flex><span>    Return,
</span></span><span style=display:flex><span>    True,
</span></span><span style=display:flex><span>    False,
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>In Python, it&rsquo;s similarly eas&ndash; uh, oh.</p><p>Python enums just don&rsquo;t work this way. <code>Enum</code> subclass members are expected to be singletons, so we&rsquo;ll have to use a different abstraction. After some finagling, I landed on <code>namedtuples</code> as a suitable alternative.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> collections <span style=color:#f92672>import</span> namedtuple
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Token</span>(TokenBase):
</span></span><span style=display:flex><span>    Ident <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Ident&#34;</span>, [<span style=color:#e6db74>&#34;value&#34;</span>])
</span></span><span style=display:flex><span>    Int <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Int&#34;</span>, [<span style=color:#e6db74>&#34;value&#34;</span>])
</span></span><span style=display:flex><span>    Illegal <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Illegal&#34;</span>, [])
</span></span><span style=display:flex><span>    Eof <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Eof&#34;</span>, [])
</span></span><span style=display:flex><span>    Assign <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Assign&#34;</span>, [])
</span></span><span style=display:flex><span>    Bang <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Bang&#34;</span>, [])
</span></span><span style=display:flex><span>    Dash <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Dash&#34;</span>, [])
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>    Return <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;Return&#34;</span>, [])
</span></span><span style=display:flex><span>    True_ <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;True_&#34;</span>, [])
</span></span><span style=display:flex><span>    False_ <span style=color:#f92672>=</span> namedtuple(<span style=color:#e6db74>&#34;False_&#34;</span>, [])
</span></span></code></pre></div><p>Not nearly as pretty, but the advantage is that each member of <code>Token</code> is now a dynamically generated <code>NamedTuple</code> that only has a <code>value</code> attribute if the token type requires it. So identifiers like <code>value</code> in <code>let value = 5;</code> are captured in <code>Token.Ident("value")</code>, but <code>return</code> tokens (<code>Token.Return()</code>) don&rsquo;t carry around extra baggage.</p><p>What&rsquo;s <code>TokenBase</code>, you ask? Well, if you instantiate a member of the <code>Token</code> class without the base class, you&rsquo;ll get something like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> Token<span style=color:#f92672>.</span>Ident(<span style=color:#e6db74>&#34;val&#34;</span>)
</span></span><span style=display:flex><span>Ident(<span style=color:#e6db74>&#34;val&#34;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> Token<span style=color:#f92672>.</span>Dash()
</span></span><span style=display:flex><span>Dash()
</span></span></code></pre></div><p>Close, but not quite as nice as the way that tokens are displayed in the Rust version: <code>Token.Ident("val")</code>. <code>TokenBase</code> customizes the <code>__repr__</code>s for each of the <code>namedtuple</code>s to look more like Rust. (It also modifies <code>__eq__</code> and <code>__neq__</code> so that empty <code>namedtuples</code> with different names do not compare equal!) Here&rsquo;s the ugliness to make that work:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>TokenBase</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init_subclass__</span>(cls) <span style=color:#f92672>-&gt;</span> <span style=color:#66d9ef>None</span>:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_token_repr</span>(self):
</span></span><span style=display:flex><span>            name <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>__class__<span style=color:#f92672>.</span>__name__
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> (
</span></span><span style=display:flex><span>                <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Token.</span><span style=color:#e6db74>{</span>name<span style=color:#e6db74>}</span><span style=color:#e6db74>(</span><span style=color:#e6db74>{</span>self<span style=color:#f92672>.</span>value<span style=color:#e6db74>!r}</span><span style=color:#e6db74>)&#34;</span>
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> hasattr(self, <span style=color:#e6db74>&#34;value&#34;</span>)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>else</span> <span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;Token.</span><span style=color:#e6db74>{</span>name<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>
</span></span><span style=display:flex><span>            )
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_token_eq</span>(self, other):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> repr(self) <span style=color:#f92672>==</span> repr(other)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_token_ne</span>(self, other):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> repr(self) <span style=color:#f92672>!=</span> repr(other)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> name, method <span style=color:#f92672>in</span> vars(cls)<span style=color:#f92672>.</span>items():
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> name<span style=color:#f92672>.</span>startswith(<span style=color:#e6db74>&#34;__&#34;</span>):
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>            method<span style=color:#f92672>.</span>__repr__ <span style=color:#f92672>=</span> _token_repr
</span></span><span style=display:flex><span>            method<span style=color:#f92672>.</span>__eq__ <span style=color:#f92672>=</span> _token_eq
</span></span><span style=display:flex><span>            method<span style=color:#f92672>.</span>__ne__ <span style=color:#f92672>=</span> _token_ne
</span></span></code></pre></div><p>The trick is that by using <code>__init_subclass__</code>, the <code>__repr__</code>, <code>__eq__</code>, and <code>__neq__</code> implementations of the <code>NamedTuple</code> class attributes on <code>Token</code> will be overwritten <em>when the class is imported</em>. This way, <code>Token.Ident(...)</code> will be modified without ever instantiating <code>Token</code>.</p><p>The end result is that instantiating members of <code>Token</code> will create <code>NamedTuple</code> instances that behave a little bit more like Rust <code>enum</code>s.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> Token<span style=color:#f92672>.</span>Ident(<span style=color:#e6db74>&#34;val&#34;</span>)
</span></span><span style=display:flex><span>Token<span style=color:#f92672>.</span>Ident(<span style=color:#e6db74>&#39;val&#39;</span>)
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> Token<span style=color:#f92672>.</span>Dash()
</span></span><span style=display:flex><span>Token<span style=color:#f92672>.</span>Dash
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> Token<span style=color:#f92672>.</span>Dash() <span style=color:#f92672>!=</span> Token<span style=color:#f92672>.</span>Return()
</span></span><span style=display:flex><span><span style=color:#66d9ef>True</span>
</span></span></code></pre></div><h2 id=shamelessly-copying-most-of-the-lexer>Shamelessly Copying (Most of) the Lexer<a hidden class=anchor aria-hidden=true href=#shamelessly-copying-most-of-the-lexer>#</a></h2><p>Though Rust is a substantially more complex language than Python and has been designed with completely different tradeoffs in mind, both languages provide similar procedural syntax. What follows is a more or less direct port of the <code>Lexer</code> struct and its methods to peek or advance to the next character in the input text.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#a6e22e>@dataclass</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>Lexer</span>:
</span></span><span style=display:flex><span>    text: str
</span></span><span style=display:flex><span>    position: int <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    read_position: int <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    ch: str <span style=color:#f92672>=</span> field(init<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>, default<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__post_init__</span>(self):
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> __iter__(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> (token <span style=color:#f92672>:=</span> self<span style=color:#f92672>.</span>next_token()) <span style=color:#f92672>!=</span> Token<span style=color:#f92672>.</span>Eof():
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>yield</span> token
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>yield</span> token
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>next_token</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>peek</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>read_position <span style=color:#f92672>&lt;</span> len(self<span style=color:#f92672>.</span>text):
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>text[self<span style=color:#f92672>.</span>read_position]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>read_char</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>read_position <span style=color:#f92672>&gt;=</span> len(self<span style=color:#f92672>.</span>text):
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>ch <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>ch <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>text[self<span style=color:#f92672>.</span>read_position]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>position <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>read_position
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>read_position <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>skip_whitespace</span>(self):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> self<span style=color:#f92672>.</span>ch<span style=color:#f92672>.</span>isspace():
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>read_ident</span>(self):
</span></span><span style=display:flex><span>        pos <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>position
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> self<span style=color:#f92672>.</span>peek()<span style=color:#f92672>.</span>isalpha() <span style=color:#f92672>or</span> self<span style=color:#f92672>.</span>peek() <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;_&#34;</span>:
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>input[pos : self<span style=color:#f92672>.</span>read_position]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>read_int</span>(self):
</span></span><span style=display:flex><span>        pos <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>position
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>while</span> self<span style=color:#f92672>.</span>peek()<span style=color:#f92672>.</span>isdigit():
</span></span><span style=display:flex><span>            self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>input[pos : self<span style=color:#f92672>.</span>read_position]
</span></span></code></pre></div><p>The <code>Lexer</code> starts at position 0 and steps through the text each time <code>next_token()</code> is called. If the next token contains multiple characters or skippable whitespace, <code>next_token()</code> will advance the <code>Lexer</code> position to the end of the last token. The <code>read_position</code> will then correspond to the start of the next token (or whitespace).</p><p>The <code>read_ident</code> and <code>read_int</code> functions repeatedly <code>peek</code> at the next character in the input text, instructing the lexer to keep reading the next character until the end of the identifer or integer. The functions record the start and end positions so that they can slice into the input string to return a multi-character token.</p><p>Python makes it easy to create custom iterables, so I added an <code>__iter__</code> method which will make <code>for token in lexer: print(token)</code> work with no extra sweat!</p><h2 id=matching-match-statements>Matching <code>match</code> statements<a hidden class=anchor aria-hidden=true href=#matching-match-statements>#</a></h2><p>Things get interesting again when trying to implement <code>next_token()</code>. The <a href=https://github.com/ThePrimeagen/ts-rust-zig-deez/blob/master/rust/src/lexer/lexer.rs#L96-L148>Rust implentation</a> uses a single <code>match</code> statement to identify each of the tokens defined in the lexer. In the python version, matching on individual characters ports directly:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>next_token</span>(self):
</span></span><span style=display:flex><span>    self<span style=color:#f92672>.</span>skip_whitespace()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>match</span> self<span style=color:#f92672>.</span>ch:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;{&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>LSquirly()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;}&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>RSquirly()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;(&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Lparen()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;)&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Rparen()
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>
</span></span></code></pre></div><p>In some cases, such as <code>Token.Bang</code>, and <code>Token.NotEqual</code>, the lexer peeks at the next character to see which token to emit. This ports over nicely as well:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;!&#34;</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>peek() <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;=&#34;</span>:
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>        tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>NotEqual()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>        tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Bang()
</span></span></code></pre></div><p>The case for finding identifiers is particularly elegant in the Rust version: the following excerpt matches on any character that contains an alphabetic character or an underscore to find identifiers, and then uses a nested match statement to identify reserved keywords.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-rust data-lang=rust><span style=display:flex><span><span style=color:#66d9ef>match</span> self.ch {
</span></span><span style=display:flex><span>    <span style=color:#f92672>..</span>.,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;a&#39;</span><span style=color:#f92672>..=</span><span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;z&#39;</span> <span style=color:#f92672>|</span> <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;A&#39;</span><span style=color:#f92672>..=</span><span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;Z&#39;</span> <span style=color:#f92672>|</span> <span style=color:#e6db74>b</span><span style=color:#e6db74>&#39;_&#39;</span> <span style=color:#f92672>=&gt;</span> {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>let</span> ident <span style=color:#f92672>=</span> self.read_ident();
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> Ok(<span style=color:#66d9ef>match</span> ident.as_str() {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;fn&#34;</span> <span style=color:#f92672>=&gt;</span> Token::Function,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;let&#34;</span> <span style=color:#f92672>=&gt;</span> Token::Let,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;if&#34;</span> <span style=color:#f92672>=&gt;</span> Token::If,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;false&#34;</span> <span style=color:#f92672>=&gt;</span> Token::False,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;true&#34;</span> <span style=color:#f92672>=&gt;</span> Token::True,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;return&#34;</span> <span style=color:#f92672>=&gt;</span> Token::Return,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;else&#34;</span> <span style=color:#f92672>=&gt;</span> Token::Else,
</span></span><span style=display:flex><span>            _ <span style=color:#f92672>=&gt;</span> Token::Ident(ident),
</span></span><span style=display:flex><span>        });
</span></span><span style=display:flex><span>    },
</span></span><span style=display:flex><span>    <span style=color:#f92672>..</span>.
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The <code>..=</code> is a convenient syntax for creating inclusive ranges that in this case span either the uppercase or lowercase alphabet. Python does not have a direct equivalent, but according to PEP 636, it does have <a href=https://peps.python.org/pep-0636/#adding-conditions-to-patterns>match conditionals</a>! Here&rsquo;s what the equivalent looks like in Python:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>case</span> t <span style=color:#66d9ef>if</span> t<span style=color:#f92672>.</span>isalpha() <span style=color:#f92672>or</span> t <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;_&#34;</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>match</span> self<span style=color:#f92672>.</span>read_ident():
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;fn&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Function()
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> _ <span style=color:#66d9ef>as</span> val:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Ident(val)
</span></span><span style=display:flex><span><span style=color:#66d9ef>case</span> t <span style=color:#66d9ef>if</span> t<span style=color:#f92672>.</span>isdigit():
</span></span><span style=display:flex><span>    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Int(self<span style=color:#f92672>.</span>read_int())
</span></span></code></pre></div><p>Incidentally, this version supports unicode alphabetic characters as well!</p><p>Putting it all together, we get:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>next_token</span>(self):
</span></span><span style=display:flex><span>    self<span style=color:#f92672>.</span>skip_whitespace()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>match</span> self<span style=color:#f92672>.</span>ch:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;{&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>LSquirly()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;}&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>RSquirly()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;(&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Lparen()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;)&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Rparen()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;,&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Comma()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;;&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Semicolon()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;+&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Plus()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;-&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Dash()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;!&#34;</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>peek() <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;=&#34;</span>:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>                tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>NotEqual()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Bang()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;&gt;&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>GreaterThan()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;&lt;&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>LessThan()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;*&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Asterisk()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;/&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>ForwardSlash()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;=&#34;</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> self<span style=color:#f92672>.</span>peek() <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;=&#34;</span>:
</span></span><span style=display:flex><span>                self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>                tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Equal()
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Assign()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> t <span style=color:#66d9ef>if</span> t<span style=color:#f92672>.</span>isalpha() <span style=color:#f92672>or</span> t <span style=color:#f92672>==</span> <span style=color:#e6db74>&#34;_&#34;</span>:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>match</span> self<span style=color:#f92672>.</span>read_ident():
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;fn&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Function()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;let&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Let()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;if&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>If()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;false&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>False_()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;true&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>True_()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;return&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Return()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;else&#34;</span>:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Else()
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>case</span> _ <span style=color:#66d9ef>as</span> val:
</span></span><span style=display:flex><span>                    tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Ident(val)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> t <span style=color:#66d9ef>if</span> t<span style=color:#f92672>.</span>isdigit():
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Int(self<span style=color:#f92672>.</span>read_int())
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> <span style=color:#e6db74>&#34;&#34;</span>:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Eof()
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>case</span> _:
</span></span><span style=display:flex><span>            tok <span style=color:#f92672>=</span> Token<span style=color:#f92672>.</span>Illegal
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    self<span style=color:#f92672>.</span>read_char()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> tok
</span></span></code></pre></div><p>Not bad!</p><h2 id=checking-our-work>Checking our work<a hidden class=anchor aria-hidden=true href=#checking-our-work>#</a></h2><p>The last task is to reimplement the tests. Here&rsquo;s the smaller of the two tests in the reference, taking advantage of the <code>__iter__</code> implementation that we added to the lexer:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>test_next_small</span>():
</span></span><span style=display:flex><span>    text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;=+()</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>,;&#34;</span>
</span></span><span style=display:flex><span>    lexer <span style=color:#f92672>=</span> Lexer(text)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    tokens <span style=color:#f92672>=</span> [
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>Assign(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>Plus(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>Lparen(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>Rparen(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>LSquirly(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>RSquirly(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>Comma(),
</span></span><span style=display:flex><span>        Token<span style=color:#f92672>.</span>Semicolon(),
</span></span><span style=display:flex><span>    ]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> exp, res <span style=color:#f92672>in</span> zip(tokens, lexer):
</span></span><span style=display:flex><span>        print(<span style=color:#e6db74>f</span><span style=color:#e6db74>&#34;expected: </span><span style=color:#e6db74>{</span>exp<span style=color:#e6db74>}</span><span style=color:#e6db74>, received </span><span style=color:#e6db74>{</span>res<span style=color:#e6db74>}</span><span style=color:#e6db74>&#34;</span>)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>assert</span> exp <span style=color:#f92672>==</span> res
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>&gt;&gt;&gt;</span> test_next_small()
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>Assign, received Token<span style=color:#f92672>.</span>Assign
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>Plus, received Token<span style=color:#f92672>.</span>Plus
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>Lparen, received Token<span style=color:#f92672>.</span>Lparen
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>Rparen, received Token<span style=color:#f92672>.</span>Rparen
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>LSquirly, received Token<span style=color:#f92672>.</span>LSquirly
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>RSquirly, received Token<span style=color:#f92672>.</span>RSquirly
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>Comma, received Token<span style=color:#f92672>.</span>Comma
</span></span><span style=display:flex><span>expected: Token<span style=color:#f92672>.</span>Semicolon, received Token<span style=color:#f92672>.</span>Semicolon
</span></span></code></pre></div><p>As usual, the full source for this post is available <a href=https://github.com/WillDuke/blog-post-code/blob/master/blog_post_code/lexer/_lexer.py>here</a>.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Many contributors <a href=https://github.com/ThePrimeagen/ts-rust-zig-deez/tree/master>submitted equivalent lexers</a> in a variety of languages for comparison, including <a href=https://github.com/ThePrimeagen/ts-rust-zig-deez/tree/master/python>one in python</a> that even includes a parser.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://willduke.github.io/posts/05-pretty-pipes/><span class=title>Next »</span><br><span>Pretty Pipes for Perusable (and Reusable) Pandas Procedures</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share A Poorman's Rust Enum in Python for ThePrimeagen's Lexer on twitter" href="https://twitter.com/intent/tweet/?text=A%20Poorman%27s%20Rust%20Enum%20in%20Python%20for%20ThePrimeagen%27s%20Lexer&amp;url=https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Poorman's Rust Enum in Python for ThePrimeagen's Lexer on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f&amp;title=A%20Poorman%27s%20Rust%20Enum%20in%20Python%20for%20ThePrimeagen%27s%20Lexer&amp;summary=A%20Poorman%27s%20Rust%20Enum%20in%20Python%20for%20ThePrimeagen%27s%20Lexer&amp;source=https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Poorman's Rust Enum in Python for ThePrimeagen's Lexer on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f&title=A%20Poorman%27s%20Rust%20Enum%20in%20Python%20for%20ThePrimeagen%27s%20Lexer"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Poorman's Rust Enum in Python for ThePrimeagen's Lexer on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Poorman's Rust Enum in Python for ThePrimeagen's Lexer on whatsapp" href="https://api.whatsapp.com/send?text=A%20Poorman%27s%20Rust%20Enum%20in%20Python%20for%20ThePrimeagen%27s%20Lexer%20-%20https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share A Poorman's Rust Enum in Python for ThePrimeagen's Lexer on telegram" href="https://telegram.me/share/url?text=A%20Poorman%27s%20Rust%20Enum%20in%20Python%20for%20ThePrimeagen%27s%20Lexer&amp;url=https%3a%2f%2fwillduke.github.io%2fposts%2f06-lexer%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://willduke-github-io.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript></article></main><footer class=footer><span>&copy; 2023 <a href=https://willduke.github.io/>Will Duke's Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>